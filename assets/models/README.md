Place local GGUF model files in this folder for on-device inference.

Default expected filename:
- tinyllama-1.1b-chat-v1.0.Q2_K.gguf

Note:
- Model binaries are intentionally git-ignored to keep repository size manageable.
